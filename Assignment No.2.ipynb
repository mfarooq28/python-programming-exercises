{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5eea293",
   "metadata": {},
   "source": [
    "# Muhammad Farooq, 182-FBAS/PHDCS/F21\n",
    "## Finding the clustering of Words in a Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f42e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               keywords  \\\n",
      "230                                                  in   \n",
      "679                                                  he   \n",
      "1774                                                the   \n",
      "2353                                                 on   \n",
      "2753                                                 an   \n",
      "...                                                 ...   \n",
      "1228                          amongstthevaluesdisplayed   \n",
      "1229                           supportingasynchronousco   \n",
      "1230  moreusablebyhavingthepotentialusertesttheproto...   \n",
      "1222                   theusersworkwithordinaryprograms   \n",
      "3230                                          similarly   \n",
      "\n",
      "      number_of_times_word_appeared        tf       idf    tf_idf  \n",
      "230                            1865  0.017991 -7.531016 -0.135490  \n",
      "679                            1805  0.017412 -7.498316 -0.130562  \n",
      "1774                           1632  0.015743 -7.397562 -0.116462  \n",
      "2353                           1554  0.014991 -7.348588 -0.110162  \n",
      "2753                           1442  0.013910 -7.273786 -0.101182  \n",
      "...                             ...       ...       ...       ...  \n",
      "1228                              1  0.000010  0.000000  0.000000  \n",
      "1229                              1  0.000010  0.000000  0.000000  \n",
      "1230                              1  0.000010  0.000000  0.000000  \n",
      "1222                              1  0.000010  0.000000  0.000000  \n",
      "3230                              1  0.000010  0.000000  0.000000  \n",
      "\n",
      "[3231 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PyPDF2\n",
    "import textract\n",
    "import re\n",
    "\n",
    "filename ='Human-Computer_Interaction.pdf' \n",
    "\n",
    "pdfFileObj = open(filename,'rb')               \n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)   \n",
    "num_pages = pdfReader.numPages                 \n",
    "\n",
    "\n",
    "count = 0\n",
    "text = \"\"\n",
    "                                                            \n",
    "while count < num_pages:                       \n",
    "    pageObj = pdfReader.getPage(count)\n",
    "    count +=1\n",
    "    text += pageObj.extractText()\n",
    "    \n",
    "if text != \"\":\n",
    "    text = text\n",
    " \n",
    "else:\n",
    "    text = textract.process('words.txt', method='tesseract', language='eng')\n",
    "\n",
    "\n",
    "text = text.encode('ascii','ignore').lower()\n",
    "text_decoded = text.decode()\n",
    "keywords = re.findall(r'[a-zA-Z]\\w+',text_decoded)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(list(set(keywords)),columns=['keywords'])\n",
    "\n",
    "\n",
    "\n",
    "def weightage(word,text,number_of_documents=1):\n",
    "    word_list = re.findall(word,text_decoded)\n",
    "    number_of_times_word_appeared =len(word_list)\n",
    "    tf = number_of_times_word_appeared/float(len(text_decoded))\n",
    "    idf = np.log((number_of_documents)/float(number_of_times_word_appeared))\n",
    "    tf_idf = tf*idf\n",
    "    return number_of_times_word_appeared,tf,idf ,tf_idf \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "df['number_of_times_word_appeared'] = df['keywords'].apply(lambda x: weightage(x,text)[0])\n",
    "df['tf'] = df['keywords'].apply(lambda x: weightage(x,text)[1])\n",
    "df['idf'] = df['keywords'].apply(lambda x: weightage(x,text)[2])\n",
    "df['tf_idf'] = df['keywords'].apply(lambda x: weightage(x,text)[3])\n",
    "\n",
    "df = df.sort_values('tf_idf',ascending=True)\n",
    "df.head(100)     \n",
    "df.to_csv('out_put.csv', index=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ded67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in text file : 182658\n"
     ]
    }
   ],
   "source": [
    "file = open(\"HCI.txt\", \"rt\", encoding='utf-8')\n",
    "data = file.read()\n",
    "words = data.split()\n",
    "\n",
    "print('Number of words in text file :', len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf6b52f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
